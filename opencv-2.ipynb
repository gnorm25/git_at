{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-21T15:36:08.995646Z","iopub.status.busy":"2024-08-21T15:36:08.995192Z","iopub.status.idle":"2024-08-21T15:36:09.717161Z","shell.execute_reply":"2024-08-21T15:36:09.716115Z","shell.execute_reply.started":"2024-08-21T15:36:08.995600Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import cv2\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T08:36:05.040464Z","iopub.status.busy":"2024-08-21T08:36:05.039980Z","iopub.status.idle":"2024-08-21T08:36:08.445385Z","shell.execute_reply":"2024-08-21T08:36:08.444019Z","shell.execute_reply.started":"2024-08-21T08:36:05.040429Z"},"trusted":true},"outputs":[],"source":["url = 'https://cobslab.com/wp-content/uploads/2022/02/ai-009-1.jpg'\n","!wget {url}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T08:36:08.449043Z","iopub.status.busy":"2024-08-21T08:36:08.448014Z","iopub.status.idle":"2024-08-21T08:36:09.153102Z","shell.execute_reply":"2024-08-21T08:36:09.151965Z","shell.execute_reply.started":"2024-08-21T08:36:08.448994Z"},"trusted":true},"outputs":[],"source":["img = cv2.imread('/kaggle/working/ai-009-1.jpg')\n","img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","plt.imshow(img)"]},{"cell_type":"markdown","metadata":{},"source":["# 정규화와 표준화"]},{"cell_type":"markdown","metadata":{},"source":["## 정규화"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T08:39:17.963936Z","iopub.status.busy":"2024-08-21T08:39:17.963355Z","iopub.status.idle":"2024-08-21T08:39:17.988680Z","shell.execute_reply":"2024-08-21T08:39:17.987286Z","shell.execute_reply.started":"2024-08-21T08:39:17.963889Z"},"trusted":true},"outputs":[],"source":["normalized_img = img / 255.0\n","print(img[0][0], normalized_img[0][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T08:39:27.543088Z","iopub.status.busy":"2024-08-21T08:39:27.542662Z","iopub.status.idle":"2024-08-21T08:39:28.333665Z","shell.execute_reply":"2024-08-21T08:39:28.332229Z","shell.execute_reply.started":"2024-08-21T08:39:27.543054Z"},"trusted":true},"outputs":[],"source":["33plt.imshow(normalized_img)"]},{"cell_type":"markdown","metadata":{},"source":["## 표준화"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T08:40:36.916759Z","iopub.status.busy":"2024-08-21T08:40:36.916200Z","iopub.status.idle":"2024-08-21T08:40:37.034573Z","shell.execute_reply":"2024-08-21T08:40:37.033260Z","shell.execute_reply.started":"2024-08-21T08:40:36.916714Z"},"trusted":true},"outputs":[],"source":["mean = np.mean(img, axis=(0, 1))\n","\n","std = np.std(img, axis=(0, 1))\n","\n","print(mean, std)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T08:41:27.040623Z","iopub.status.busy":"2024-08-21T08:41:27.040140Z","iopub.status.idle":"2024-08-21T08:41:27.103994Z","shell.execute_reply":"2024-08-21T08:41:27.102717Z","shell.execute_reply.started":"2024-08-21T08:41:27.040585Z"},"trusted":true},"outputs":[],"source":["# "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T08:41:56.566778Z","iopub.status.busy":"2024-08-21T08:41:56.566243Z","iopub.status.idle":"2024-08-21T08:41:57.279660Z","shell.execute_reply":"2024-08-21T08:41:57.278476Z","shell.execute_reply.started":"2024-08-21T08:41:56.566729Z"},"trusted":true},"outputs":[],"source":["plt.imshow(standardized_img)"]},{"cell_type":"markdown","metadata":{},"source":["# 필터링"]},{"cell_type":"markdown","metadata":{},"source":["## Salt and Pepper Noise"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T08:43:11.920701Z","iopub.status.busy":"2024-08-21T08:43:11.920237Z","iopub.status.idle":"2024-08-21T08:43:11.927708Z","shell.execute_reply":"2024-08-21T08:43:11.926598Z","shell.execute_reply.started":"2024-08-21T08:43:11.920637Z"},"trusted":true},"outputs":[],"source":["def generate_salt_noise(image):\n","    num_salt = np.ceil(0.05 * image.size)\n","    coords = [np.random.randint(0, i - 1, int(num_salt))\n","              for i in image.shape]\n","    salted_image = image.copy()\n","    salted_image[coords[0], coords[1]] = 255\n","    return salted_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T08:43:15.234825Z","iopub.status.busy":"2024-08-21T08:43:15.234303Z","iopub.status.idle":"2024-08-21T08:43:15.242121Z","shell.execute_reply":"2024-08-21T08:43:15.240732Z","shell.execute_reply.started":"2024-08-21T08:43:15.234782Z"},"trusted":true},"outputs":[],"source":["def generate_pepper_noise(image):\n","    num_pepper = np.ceil(0.05 * image.size)\n","    coords = [np.random.randint(0, i - 1, int(num_pepper))\n","              for i in image.shape]\n","    peppered_image = image.copy()\n","    peppered_image[coords[0], coords[1]] = 0\n","    return peppered_image"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T08:43:39.863396Z","iopub.status.busy":"2024-08-21T08:43:39.862850Z","iopub.status.idle":"2024-08-21T08:43:41.334453Z","shell.execute_reply":"2024-08-21T08:43:41.333046Z","shell.execute_reply.started":"2024-08-21T08:43:39.863351Z"},"trusted":true},"outputs":[],"source":["!wget https://raw.githubusercontent.com/Cobslab/imageBible/main/image/like_lenna.png"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T09:57:58.676788Z","iopub.status.busy":"2024-08-21T09:57:58.676291Z","iopub.status.idle":"2024-08-21T09:57:58.682024Z","shell.execute_reply":"2024-08-21T09:57:58.680937Z","shell.execute_reply.started":"2024-08-21T09:57:58.676746Z"},"trusted":true},"outputs":[],"source":["lenna_path = '/kaggle/working/like_lenna.png'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T08:43:59.177666Z","iopub.status.busy":"2024-08-21T08:43:59.177120Z","iopub.status.idle":"2024-08-21T08:43:59.218935Z","shell.execute_reply":"2024-08-21T08:43:59.217625Z","shell.execute_reply.started":"2024-08-21T08:43:59.177601Z"},"trusted":true},"outputs":[],"source":["lenna_image = cv2.imread(lenna_path, cv2.IMREAD_GRAYSCALE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T08:44:12.689920Z","iopub.status.busy":"2024-08-21T08:44:12.689388Z","iopub.status.idle":"2024-08-21T08:44:13.908334Z","shell.execute_reply":"2024-08-21T08:44:13.906917Z","shell.execute_reply.started":"2024-08-21T08:44:12.689879Z"},"trusted":true},"outputs":[],"source":["#\n","#\n","filtered_lenna = cv2.medianBlur(peppered_lenna, 5)\n","\n","\n","fig, axes = plt.subplots(1, 4, figsize=(20, 6))\n","\n","import matplotlib.pyplot as plt\n","\n","axes[0].imshow(lenna_image, cmap='gray')\n","axes[0].set_title('Original Lenna Image')\n","axes[0].axis('off')\n","\n","axes[1].imshow(salted_lenna, cmap='gray')\n","axes[1].set_title('Salted Lenna Image')\n","axes[1].axis('off')\n","\n","axes[2].imshow(peppered_lenna, cmap='gray')\n","axes[2].set_title('Salted & Peppered Lenna')\n","axes[2].axis('off')\n","\n","axes[3].imshow(filtered_lenna, cmap='gray')\n","axes[3].set_title('Median Filtered Lenna')\n","axes[3].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# 가우시안 필터링"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T08:50:07.216859Z","iopub.status.busy":"2024-08-21T08:50:07.216266Z","iopub.status.idle":"2024-08-21T08:50:07.633518Z","shell.execute_reply":"2024-08-21T08:50:07.631859Z","shell.execute_reply.started":"2024-08-21T08:50:07.216811Z"},"trusted":true},"outputs":[],"source":["image = cv2.imread(lenna_path, cv2.IMREAD_GRAYSCALE)\n","\n","mean = 0\n","sigma = 1\n","gaussian_noise = np.random.normal(mean, sigma, image.shape).astype('uint8')\n","noisy_image = cv2.add(image, gaussian_noise)\n","\n","plt.imshow(noisy_image, cmap='gray')\n","plt.title('Noisy Image')\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T09:03:31.946791Z","iopub.status.busy":"2024-08-21T09:03:31.946238Z","iopub.status.idle":"2024-08-21T09:03:33.552462Z","shell.execute_reply":"2024-08-21T09:03:33.551183Z","shell.execute_reply.started":"2024-08-21T09:03:31.946740Z"},"trusted":true},"outputs":[],"source":["#\n","denoised_images = []\n","\n","for sigma in sigma_values:\n","    denoised = cv2.GaussianBlur(noisy_image, (0, 0), sigma)\n","    denoised_images.append(denoised)\n","\n","fig, axes = plt.subplots(1, 4, figsize=(20, 10))\n","\n","axes[0].imshow(noisy_image, cmap='gray')\n","axes[0].set_title('Noisy Image')\n","axes[0].axis('off')\n","\n","for ax, img, sigma in zip(axes[1:], denoised_images, sigma_values):\n","    ax.imshow(img, cmap='gray')\n","    ax.set_title(f'Denoised (σ={sigma})')\n","    ax.axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# 변환"]},{"cell_type":"markdown","metadata":{},"source":["## 원근 변환"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T09:10:52.273010Z","iopub.status.busy":"2024-08-21T09:10:52.271471Z","iopub.status.idle":"2024-08-21T09:10:53.798743Z","shell.execute_reply":"2024-08-21T09:10:53.797150Z","shell.execute_reply.started":"2024-08-21T09:10:52.272952Z"},"trusted":true},"outputs":[],"source":["!wget https://raw.githubusercontent.com/Lilcob/test_colab/main/perspective_test.jpg"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T09:11:19.274788Z","iopub.status.busy":"2024-08-21T09:11:19.274236Z","iopub.status.idle":"2024-08-21T09:11:20.413242Z","shell.execute_reply":"2024-08-21T09:11:20.411865Z","shell.execute_reply.started":"2024-08-21T09:11:19.274739Z"},"trusted":true},"outputs":[],"source":["# 이미지 로드\n","image_path = '/kaggle/working/perspective_test.jpg'\n","new_source_image = cv2.imread(image_path)\n","\n","# 지정한 꼭지점 좌표 (좌표 순서 변경)\n","ordered_corners = np.array([[57, 630], [936, 330], [1404, 792], [550, 1431]], dtype='float32')\n","\n","# 너비와 높이 계산\n","ordered_width = int(max(np.linalg.norm(ordered_corners[0] - ordered_corners[1]),\n","                        np.linalg.norm(ordered_corners[2] - ordered_corners[3])))\n","ordered_height = int(max(np.linalg.norm(ordered_corners[0] - ordered_corners[3]),\n","                         np.linalg.norm(ordered_corners[1] - ordered_corners[2])))\n","\n","# 변환이 될 꼭지점 좌표 지정\n","ordered_rect_corners = np.array([[0, 0], [ordered_width, 0], [ordered_width, ordered_height], [0, ordered_height]], dtype='float32')\n","\n","# 호모그래피 행렬 계산\n","ordered_scan_matrix = cv2.getPerspectiveTransform(ordered_corners, ordered_rect_corners)\n","\n","# 원근 변환 다시 적용\n","ordered_scanned_image = cv2.warpPerspective(new_source_image, ordered_scan_matrix, (ordered_width, ordered_height))\n","\n","# 스캔된 이미지 다시 출력\n","plt.figure(figsize=(10, 5))\n","plt.subplot(1, 2, 1)\n","plt.title(\"New Source Image\")\n","plt.imshow(cv2.cvtColor(new_source_image, cv2.COLOR_BGR2RGB))\n","plt.subplot(1, 2, 2)\n","plt.title(\"Ordered Scanned Image\")\n","plt.imshow(cv2.cvtColor(ordered_scanned_image, cv2.COLOR_BGR2RGB))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# 이미지 피라미드"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T09:32:31.015161Z","iopub.status.busy":"2024-08-21T09:32:31.014739Z","iopub.status.idle":"2024-08-21T09:32:32.256776Z","shell.execute_reply":"2024-08-21T09:32:32.255603Z","shell.execute_reply.started":"2024-08-21T09:32:31.015125Z"},"trusted":true},"outputs":[],"source":["image = cv2.imread(lenna_path, cv2.IMREAD_COLOR)\n","\n","image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","def gaussian_pyramid(image, levels):\n","    pyramid = [image]\n","    for i in range(levels-1):\n","        image = cv2.pyrDown(image)\n","        pyramid.append(image)\n","    return pyramid\n","\n","levels = 5\n","pyramid = gaussian_pyramid(image_rgb, levels)\n","\n","# 가우시안 피라미드를 시각화\n","fig, axes = plt.subplots(1, levels, figsize=(20, 8))\n","for i, ax in enumerate(axes):\n","    ax.imshow(pyramid[i])\n","    ax.axis('off')\n","    ax.set_title(f'Level {i+1}')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# 경계 검출(Edge Detection)\n","\n","## Canny Edge Detection"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T09:35:00.218761Z","iopub.status.busy":"2024-08-21T09:35:00.218327Z","iopub.status.idle":"2024-08-21T09:35:01.438500Z","shell.execute_reply":"2024-08-21T09:35:01.437377Z","shell.execute_reply.started":"2024-08-21T09:35:00.218726Z"},"trusted":true},"outputs":[],"source":["image = cv2.imread(lenna_path, cv2.IMREAD_COLOR)\n","\n","image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","# 가우시안 블러 적용\n","blurred_image = cv2.GaussianBlur(image_rgb, (5, 5), 1.4)\n","\n","# 2. 캐니 에지 검출\n","canny_edges = cv2.Canny(blurred_image, threshold1=50, threshold2=150)\n","\n","#3. 시각화\n","fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","axes[0].imshow(image_rgb)\n","axes[0].axis('off')\n","axes[0].set_title('Original Image')\n","axes[1].imshow(blurred_image)\n","axes[1].axis('off')\n","axes[1].set_title('Gaussian Blurred Image')\n","axes[2].imshow(canny_edges, cmap='gray')\n","axes[2].axis('off')\n","axes[2].set_title('Canny Edge Detection')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T09:35:14.630870Z","iopub.status.busy":"2024-08-21T09:35:14.630373Z","iopub.status.idle":"2024-08-21T09:35:15.550888Z","shell.execute_reply":"2024-08-21T09:35:15.549726Z","shell.execute_reply.started":"2024-08-21T09:35:14.630834Z"},"trusted":true},"outputs":[],"source":["# 다양한 임계값 조합으로 캐니 에지 검출 수행\n","thresholds = [(10, 50), (50, 100), (100, 150), (150, 200)]\n","\n","canny_results = []\n","\n","for threshold1, threshold2 in thresholds:\n","    canny_image = cv2.Canny(blurred_image, threshold1=threshold1, threshold2=threshold2)\n","    canny_results.append(canny_image)\n","\n","# 시각화\n","fig, axes = plt.subplots(1, len(thresholds), figsize=(20, 5))\n","\n","for i, ax in enumerate(axes):\n","    ax.imshow(canny_results[i], cmap='gray')\n","    ax.axis('off')\n","    ax.set_title(f'threshold1={thresholds[i][0]}, threshold2={thresholds[i][1]}')"]},{"cell_type":"markdown","metadata":{},"source":["## Prewitt Edge Detection\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T09:36:42.169998Z","iopub.status.busy":"2024-08-21T09:36:42.169581Z","iopub.status.idle":"2024-08-21T09:36:42.427977Z","shell.execute_reply":"2024-08-21T09:36:42.426869Z","shell.execute_reply.started":"2024-08-21T09:36:42.169966Z"},"trusted":true},"outputs":[],"source":["image = cv2.imread(lenna_path, cv2.IMREAD_GRAYSCALE)\n","\n","# 프리윗 커널 정의\n","kx = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]])\n","ky = np.array([[-1, -1, -1], [0, 0, 0], [1, 1, 1]])\n","\n","# 프리윗 커널 적용\n","gx = cv2.filter2D(image, -1, kx)\n","gy = cv2.filter2D(image, -1, ky)\n","\n","# 결과 이미지\n","prewitt_result = cv2.addWeighted(gx, 0.5, gy, 0.5, 0)\n","\n","# 결과 출력\n","plt.imshow(prewitt_result, cmap='gray')\n","plt.axis('off')\n","plt.title('Prewitt Edge Detection')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Sobel Edge Detection"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T09:36:49.003669Z","iopub.status.busy":"2024-08-21T09:36:49.003184Z","iopub.status.idle":"2024-08-21T09:36:49.324088Z","shell.execute_reply":"2024-08-21T09:36:49.322756Z","shell.execute_reply.started":"2024-08-21T09:36:49.003613Z"},"trusted":true},"outputs":[],"source":["# 소벨 커널 적용\n","gx_sobel = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n","gy_sobel = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n","\n","# 결과 이미지\n","sobel_result = cv2.addWeighted(gx_sobel, 0.5, gy_sobel, 0.5, 0)\n","\n","# 결과 출력\n","plt.imshow(sobel_result, cmap='gray')\n","plt.axis('off')\n","plt.title('Sobel Edge Detection')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Hough Transform\n","허프 변환(Hough Transform)은 이미지에서 선을 검출하는 데 사용됩니다. `cv2.HoughLinesP` 함수는 일반적인 허프 변환과 달리 선의 시작점과 끝점을 반환하므로, 특정 길이 이상의 선을 찾는 데 유용합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T11:44:08.220189Z","iopub.status.busy":"2024-08-21T11:44:08.219687Z","iopub.status.idle":"2024-08-21T11:44:09.581288Z","shell.execute_reply":"2024-08-21T11:44:09.579994Z","shell.execute_reply.started":"2024-08-21T11:44:08.220149Z"},"trusted":true},"outputs":[],"source":["!wget -O football_stadium.jpg \"https://www.arsenal.com/sites/default/files/styles/link_image_extra_large/public/images/GettyImages-884411976.jpg?auto=webp&itok=w7-4LWKS\"\n","\n","football_stadium_path = '/kaggle/working/football_stadium.jpg'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T11:45:53.924843Z","iopub.status.busy":"2024-08-21T11:45:53.924354Z","iopub.status.idle":"2024-08-21T11:45:54.733917Z","shell.execute_reply":"2024-08-21T11:45:54.732732Z","shell.execute_reply.started":"2024-08-21T11:45:53.924806Z"},"trusted":true},"outputs":[],"source":["image = cv2.imread(football_stadium_path, cv2.IMREAD_COLOR)\n","gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","plt.imshow(gray, cmap='gray')\n","plt.axis('off')\n","plt.title('Original Image')\n","plt.show()\n","\n","# Canny 에지 검출\n","edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n","\n","# 확장된 허프 변환을 사용하여 선 검출\n","lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180, threshold=100, minLineLength=50, maxLineGap=10)\n","\n","# 검출된 선을 원본 이미지 위에 그리기\n","if lines is not None:\n","    for line in lines:\n","        x1, y1, x2, y2 = line[0]\n","        cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # 선을 녹색으로 그리기\n","\n","# 결과 이미지 시각화\n","plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","plt.axis('off')\n","plt.title('Detected Lines using HoughLinesP')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# 이미지 마스킹\n","`cv2.inRange()` 함수는 OpenCV에서 특정 색상 범위 내에 있는 픽셀을 찾아서 이진화 마스크를 생성하는 데 사용됩니다. 이 함수는 입력 이미지에서 지정된 범위 내의 색상을 가진 픽셀을 찾고, 그 범위에 속하는 픽셀은 255(흰색), 나머지 픽셀은 0(검정색)으로 설정된 마스크 이미지를 반환합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T12:26:39.057447Z","iopub.status.busy":"2024-08-21T12:26:39.057027Z","iopub.status.idle":"2024-08-21T12:26:39.565120Z","shell.execute_reply":"2024-08-21T12:26:39.563715Z","shell.execute_reply.started":"2024-08-21T12:26:39.057411Z"},"trusted":true},"outputs":[],"source":["image = cv2.imread(football_stadium_path, cv2.IMREAD_COLOR)\n","plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","plt.axis('off')\n","plt.title('Original Image')\n","plt.show()\n","\n","hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n","\n","# 붉은색 범위\n","lower_red = np.array([-30, 0, 0])\n","upper_red = np.array([30, 255, 255])\n","\n","# 붉은 범위에 해당하는 마스크 생성\n","mask = cv2.inRange(hsv, lower_red, upper_red)\n","\n","# 원본 이미지에서 붉은 부분만 추출\n","# 첫 번째 image와, 두 번째 image+mask 사이의 교집합\n","result = cv2.bitwise_and(image, image, mask=mask)\n","\n","plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n","plt.axis('off')\n","plt.title('Masked Image')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# 히스토그램 분석\n","OpenCV에서 히스토그램 연산을 하는 이유는 이미지의 픽셀 값 분포를 분석하고, 이를 통해 이미지의 특성을 파악하거나, 이미지 처리 작업에서 필요한 정보를 얻기 위해서입니다. 히스토그램은 이미지에서 각 픽셀 값이 얼마나 자주 나타나는지를 그래프로 나타낸 것으로, 이미지의 밝기, 대비, 색상 분포 등을 이해하는 데 유용합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T09:48:08.478875Z","iopub.status.busy":"2024-08-21T09:48:08.478298Z","iopub.status.idle":"2024-08-21T09:48:09.447838Z","shell.execute_reply":"2024-08-21T09:48:09.446724Z","shell.execute_reply.started":"2024-08-21T09:48:08.478828Z"},"trusted":true},"outputs":[],"source":["image = cv2.imread(lenna_path, cv2.IMREAD_COLOR)\n","plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","plt.axis('off')\n","plt.title('Original Image')\n","plt.show()\n","\n","# BGR 채널로 분리\n","channels = cv2.split(image) # 이미지 채널 별 분리\n","colors = ('b', 'g', 'r')\n","plt.figure(figsize=(10, 6))\n","\n","# 각 채널에 대해 히스토그램 계산 및 시각화\n","for (channel, color) in zip(channels, colors):\n","    # calcHist(채널, 인덱스, 마스크, 히스토그램 빈 수, 픽셀 범위)\n","    hist = cv2.calcHist([channel], [0], None, [256], [0, 256])\n","    plt.plot(hist, color=color)\n","\n","# 그래프 제목과 레이블 설정\n","plt.title('Color Histogram for BGR Image')\n","plt.xlabel('Pixel Intensity')\n","plt.ylabel('Frequency')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T10:19:38.678769Z","iopub.status.busy":"2024-08-21T10:19:38.678271Z","iopub.status.idle":"2024-08-21T10:19:39.473979Z","shell.execute_reply":"2024-08-21T10:19:39.472750Z","shell.execute_reply.started":"2024-08-21T10:19:38.678734Z"},"trusted":true},"outputs":[],"source":["# 동일한 이미지에 대하여 가우시안 필터를 적용한 뒤 히스토그램 비교해보기"]},{"cell_type":"markdown","metadata":{},"source":["# Thresholding\n","주로 그레이스케일 이미지에서 특정 임계값(threshold)을 기준으로 픽셀을 이진화(binary)하는 과정입니다. 이 과정은 이미지를 흑백으로 변환하거나, 특정 영역을 분리하는 데 사용됩니다. 예를 들어, 문서 스캔 이미지에서 텍스트와 배경을 분리하거나, 객체를 추출할 때 사용됩니다."]},{"cell_type":"markdown","metadata":{},"source":["## Binary Thresholding"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T10:09:40.158921Z","iopub.status.busy":"2024-08-21T10:09:40.158438Z","iopub.status.idle":"2024-08-21T10:09:40.378559Z","shell.execute_reply":"2024-08-21T10:09:40.377077Z","shell.execute_reply.started":"2024-08-21T10:09:40.158885Z"},"trusted":true},"outputs":[],"source":["img = cv2.imread(lenna_path, cv2.IMREAD_GRAYSCALE)\n","\n","ret, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n","\n","plt.imshow(th1, cmap='gray')\n","plt.axis('off')\n","plt.title('Global Thresholding (v = 127)')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Adaptive Thresholding\n","\n","Adaptive Thresholding(적응형 임계값 처리)은 이미지에서 조명 조건이 균일하지 않을 때 효과적으로 사용할 수 있는 기법입니다. 일반적인 Thresholding 방법이 이미지 전체에 동일한 임계값을 적용하는 반면, Adaptive Thresholding은 이미지의 작은 영역마다 서로 다른 임계값을 적용하여 이진화 처리를 수행합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T09:58:22.024033Z","iopub.status.busy":"2024-08-21T09:58:22.022880Z","iopub.status.idle":"2024-08-21T09:58:22.618510Z","shell.execute_reply":"2024-08-21T09:58:22.617230Z","shell.execute_reply.started":"2024-08-21T09:58:22.023981Z"},"trusted":true},"outputs":[],"source":["img = cv2.imread(lenna_path, cv2.IMREAD_GRAYSCALE)\n","\n","\n","img = cv2.medianBlur(img, 5)\n"," \n","ret, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n","\n","th2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \\\n","            cv2.THRESH_BINARY, 11, 2)\n","\n","th3 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \\\n","            cv2.THRESH_BINARY, 11, 2)\n"," \n","titles = ['Original Image', 'Global Thresholding (v = 127)',\n","            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n","\n","images = [img, th1, th2, th3]\n"," \n","for i in range(4):\n","    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n","    plt.title(titles[i])\n","    plt.xticks([]),plt.yticks([])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Otsu's Thresholding\n","\n","Otsu's Thresholding은 이미지 이진화에 사용되는 자동 임계값 결정 기법입니다. Otsu의 방법은 이미지의 히스토그램을 분석하여 클래스 간의 분산이 최대가 되는 임계값을 자동으로 선택합니다. 이 방법은 이미지의 밝기 분포에 따라 최적의 임계값을 계산하므로, 사용자가 임계값을 수동으로 설정할 필요 없이 효과적으로 이진화를 수행할 수 있습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T10:20:23.034832Z","iopub.status.busy":"2024-08-21T10:20:23.034200Z","iopub.status.idle":"2024-08-21T10:20:26.274871Z","shell.execute_reply":"2024-08-21T10:20:26.272885Z","shell.execute_reply.started":"2024-08-21T10:20:23.034776Z"},"trusted":true},"outputs":[],"source":["img = cv2.imread(lenna_path, cv2.IMREAD_GRAYSCALE)\n"," \n","# global thresholding\n","ret1,th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n"," \n","# Otsu's thresholding\n","ret2,th2 = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n"," \n","# Otsu's thresholding after Gaussian filtering\n","blur = cv2.GaussianBlur(img, (5,5), 0)\n","ret3,th3 = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n"," \n","# plot all the images and their histograms\n","images = [img, 0, th1,\n","          img, 0, th2,\n","          blur, 0, th3]\n","titles = ['Original Noisy Image','Histogram','Global Thresholding (v=127)',\n","          'Original Noisy Image','Histogram',\"Otsu's Thresholding\",\n","          'Gaussian filtered Image','Histogram',\"Otsu's + Gaussian\"]\n"," \n","for i in range(3):\n","    plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray')\n","    plt.title(titles[i*3]), plt.xticks([]), plt.yticks([])\n","    plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)\n","    plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([])\n","    plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray')\n","    plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Image Segmentation"]},{"cell_type":"markdown","metadata":{},"source":["## Watershed Algorithm\n","\n","이미지 처리에서 객체의 경계를 감지하고 분할하는 데 사용되는 강력한 기법입니다. 이 알고리즘의 이름은 물이 지형을 따라 흐르는 방식을 시뮬레이션하는 방식에서 유래했습니다. 이미지를 지형으로 간주하고, 물이 낮은 지점부터 흘러가는 것을 시뮬레이션하여 서로 다른 객체를 분리합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T11:14:51.346681Z","iopub.status.busy":"2024-08-21T11:14:51.345235Z","iopub.status.idle":"2024-08-21T11:14:52.779393Z","shell.execute_reply":"2024-08-21T11:14:52.777793Z","shell.execute_reply.started":"2024-08-21T11:14:51.346605Z"},"trusted":true},"outputs":[],"source":["coin_url = \"https://docs.opencv.org/4.x/water_coins.jpg\"\n","!wget {coin_url} -O coin.jpg\n","\n","coin_path = '/kaggle/working/coin.jpg'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T11:17:18.261230Z","iopub.status.busy":"2024-08-21T11:17:18.260727Z","iopub.status.idle":"2024-08-21T11:17:18.723508Z","shell.execute_reply":"2024-08-21T11:17:18.722223Z","shell.execute_reply.started":"2024-08-21T11:17:18.261191Z"},"trusted":true},"outputs":[],"source":["image = cv2.imread(coin_path, cv2.IMREAD_COLOR)\n","plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","plt.axis('off')\n","plt.title('Original Image')\n","plt.show()\n","\n","gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n","\n","plt.imshow(thresh, cmap='gray')\n","plt.axis('off')\n","plt.title('Otsu Thresholding')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# 미니 프로젝트 - Lane Detection\n"]},{"cell_type":"markdown","metadata":{},"source":["- 제시된 동영상 파일에서 차선을 검출하여 gif로 변환하는 코드를 작성해주세요.\n","\n","- 아래 지침에 따라 코드를 설계해주세요.\n","\n","1. 동영상 파일을 연 후, 각 프레임마다 특정 색상을 검출합니다.\n","\n","2. 색상을 검출하기 위하여 이미지를 HSV 형식으로 변환합니다.\n","\n","3. 흰 부분의 값을 HSV로 정의하고, 이를 에지 검출 알고리즘으로 분리합니다.\n","\n","4. 분리된 선을 바탕으로 허프 변환을 가합니다.\n","\n","5. 처리된 각 프레임을 RGB로 변환합니다.\n","\n","6. imageio.mimsave 메서드로 여러 프레임을 gif로 변환합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-21T12:01:45.827919Z","iopub.status.busy":"2024-08-21T12:01:45.827351Z","iopub.status.idle":"2024-08-21T12:03:49.731195Z","shell.execute_reply":"2024-08-21T12:03:49.729956Z","shell.execute_reply.started":"2024-08-21T12:01:45.827876Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5574328,"sourceId":9217973,"sourceType":"datasetVersion"},{"datasetId":5575344,"sourceId":9219415,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
